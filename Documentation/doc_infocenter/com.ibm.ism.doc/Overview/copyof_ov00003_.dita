<?xml version="1.0" encoding="UTF-8"?>
<!--Arbortext, Inc., 1988-2011, v.4002-->
<!DOCTYPE concept PUBLIC  "-//OASIS//DTD DITA Concept//EN"
 "concept.dtd">
<?Pub Inc?>
<concept id="ov00003_" xml:lang="en-us">
<title>Key Concepts</title>
<shortdesc>An introduction to terminology and concepts associated
with ISM.</shortdesc>
<conbody>
<section></section>
<section><title>Security</title><p>SSL</p><p>Messaging Policy</p><p
>Connection Policy</p></section>
<section><title>Supported Protocols</title><p>MQTT</p><p>WebSockets</p
><p>JMS</p><p>Spk to Ken B.</p><p>The first release of Niagara will
support the following clients: </p><p>•    JMS – connecting over a
proprietary high performance wireline protocol written specifically
to achieve high message rates. This client stack should be shipped
with Niagara and separately downloadable.</p><p> •    MQTT C client.
This is the (open) standard transport protocol – i.e. MQTT over TCP/IP.
This is a standard client – it could ship with Niagara, but will also
be separately downloadable.</p><p> •    MQTT client for Java. This
is the (open) standard transport protocol – i.e. MQTT over TCP/IP.
This is a standard client – it could ship with Niagara, but will also
be separately downloadable. </p><p>•    MQTT client for .NET – this
is a native C client that uses the open standard MQTT over TCP/IP. </p
><p>•    MQTT tunnelled through websockets (wss). This enables a pure
Javascript client to be created, which can be downloaded into a mobile
device’s browser. This provides a zero-install client capability.</p
></section>
<section><title>Messaging Hub</title></section>
<section><title>Endpoints</title></section>
<section><title>MQ Bridge</title><p>Where ISM and MQ are used in the
same solution, they can be inter-connected, but they perform distinct
roles. </p><p>ISM is being brought to market as an edge concentrator
that can support connections from large numbers of mobile or IoT devices
or clients, generally from outside the enterprise, but they could
be "on the inside".  MQ is flexible, general purpose messaging middleware
that enables a customer to run on just about every platform of interest,
and supports the relevent APIs and language environments.  It is to
MQ that customers will generally connect their enterprise applications,
running in CICS, IMS, WAS and a host of other application environments.
ISM majors on supporting protocol-attached clients with the emphasis
on protocols well-suited to mobile and IoT applications - such as
MQTT and websockets, but see the Protocols section of the Specification
for details. In contrast, MQ majors on supporting a common messaging
programming interface across platforms and runtimes and internally
uses proprietary MQ client and server FAPs ("fap" = "format and protocol")
as well as (open) MQTT protocol for telemetry (IoT). </p><p>ISM clients
connect to ISM and produce or consume  messages sent to or from ISM
destinations. WMQ clients connect to an MQ queue manager (QM) and
produce or consume  messages sent to or from MQ destinations. </p
><p>There will be applications for which messages sent by an ISM client
(to an ISM destination) need to be forwarded to (or require a message
to be sent to) an MQ destination, and vice versa. To support these
applications, an MQ Bridge can be run on the ISM appliance. The bridge
enables an MQ client to consume messages produced by ISM clients and
vice versa. </p><p>MQ clients will be able to consume messages which
were sent to ISM destinations and produce messages which end up on
ISM destinations. The MQ applications will have been written and configured
 to know about MQ - they should not and will not know about ISM or
ISM destinations. The applications will put to an MQ queue or publish
to a topic hosted by MQ - and will not be aware that there is a bridge
that is taking those messages and forwarding them to ISM. Likewise,
in the other direction the MQ clients will believe that they are receiving
from MQ destinations (because that's all they can do). </p><p>The
bridge will only run if there is at least one MQ connection configured
in the ISM appliance config. </p><p>The bridge will connect to one
or more MQ Queue Manager. </p><p>There are existing customers who
use MQ as a backbone for enterprise messaging and are moving to support
new mobile applications or sensing and actuation of devices.</p><p
>There are also customers who are already have mobile or Internet
of Things applications, connecting to MQ  - but who need to scale
their deployments up to levels that would go beyond what's "reasonable"
with MQ 7.1/7.5 (the currently most recent releases of MQ as we develop
ISM).</p><p>There are also customers who do not yet use MQ - we'll
assume that they are already (or soon will be) deploying mobile/IoT
applications and need to be able to connect enterprise applications
to the "server-side" that will push notifications or requests out
to devices or receive messages arising from the devices.</p><p>So,
we should aim to cover big MQ users, and MQ users who are scaling
up, plus people to whom MQ is new. </p></section><?Pub Caret -1?>
<section><title>administrative concepts and scalability of administration</title
><p>Niagara is being designed to scale to handle large numbers of
users, connections, destinations and subscriptions.  The administrative
interface and underlying model will be used for configuration, control
and monitoring of large numbers of these types of objects and will
need to allow an administrative user to perform the above types of
task in a tractable manner. For example, it will not be appropriate
to present lists or trees of all objects of a given type or within
a given scope. The user interface will need to provide more sophisticated
concepts and mechanisms to enable the administrative user to avoid
having to iterate over large numbers of objects</p><p>There will be
a need for both graphical and scripting/command line interfaces. For
administration some people like GUIs but others do not allow definitions
from a GUI and require that all changes must be made through a script
so that the changes can be tested in pre-production systems, and can
be inspected. Also if an administrator needs to make 1000s of changes
they generally want to script them rather than use a GUI. The following
text should be interpreted as applying to both graphical and scripting/command
line interfaces.  If the ISM admin interface were based simply around
lists of objects (e.g. in a web console) it would be doomed to fail
– for the same reasons as the WAS admin console and the first attempt
at a BPM web console.  The BPM UI team moved on to a more portal style
interface (in BPM 8.0) which supports tagging and queries etc. That
may not be appropriate for Niagara, but it is worth being aware that
other teams have battled with similar issues. The Niagara administrative
interface will need to support aggregation and drill-down; allowing
the creation of queries, conditions or subscriptions against groups
of objects that need to be monitored or operated on.  There are many
examples which include control or interrogation of one or a small
number of objects, up to aggregated control or monitoring of large
sets of objects. At this ‘object-specific’ end of the spectrum, an
administrator may, for example, want to view the status of an individual
channel (as a result of a complaint or enquiry from a user of that
channel for example), or the administrator may want to stop a particular
channel (as part of a system shut down). There will also be situations
when an administrator wants to monitor or operate on sets of objects,
which could potentially be quite large (e.g. “Which channels have
stopped recently?”, “Which channels have reported errors?” or “How
many channels have been connected for more than 1 hour (so are unlikely
to shut down in next 10 minutes)?” The administrator may want to see
an aggregated view of the status of all queues on a particular appliance
- where the set could be constructed using a conditional expression
that the user can configure - e.g. "if any queue in this set has a
message older than 1 hour then indicate that the set (of queues) contains
something I should investigate". Or, "if any subscription related
to this topic has a backlog of more than 100 unread publications then
indicate that there is something about the topic that I should be
aware of".  And in either example the user is likely to want the ability
to drill down into the set of queues or the topic tree to locate and
identify the "problem". Aggregations could be useful in reducing the
number of things the user is expected to operate on or monitor - e.g.
"show me all connections from a certain ipaddress", or "show me all
connections that are driving messages onto a certain queue".  With
large sets of objects, it follows that much of the processing for
the administrative operations will have to take place on the appliance
itself, rather than in the web browser or admin client system. It
will be far more efficient to derive a result set (e.g. containing
50 records) on the appliance and then pass those 50 records to the
administrative interface - instead of passing back the set of all
objects and expecting to filter them at the admin client (browser).
Even a restricted set of 50 objects may amount to 50Kbytes if each
record is 1KB. We absolutely would not want to pass 1M x 1KB records
to the administrative client (GUI or scripted) and apply the filtering
or aggregation at the client. This becomes even more important if
the data are to be refreshed every second or so – otherwise the aggregate
data rate to the administrative client would become unsustainable.
The consequence of this observation is that the processing logic for
retrieving and returning the data from administrative queries or subscriptions
must be integrated with the internal data structures, so it can quickly
crawl through those structures and select only those records of interest,
rather than format and return a huge number of records – most of which
would be thrown away at the client.  Response times are important
and an administrator may expect normal response time to be approximately
0.5 second after they click or press the enter key.  A long response
time would be 5 seconds. Anything longer and the user will have assumed
that the system has hung. A consequence of this is that, in addition
to the need for filtering and aggregation to be performed on the appliance,
if the appliance still needs to return a result set that is “larger
than a screenful” (deliberately vague) then it is preferable to return
the first 50 or 100 records and limit the display (e.g. "Showing 100
of 10,000 results") and have an option to display “more results” or
to “display all results”. The ordering of results can be helpful here,
making it possible to request and display “the 100 most subscribed
topics” or “the 100 most published to topics". This means the appliance
needs to either store the data in the right order internally, or be
able to create a result set in a particular order.  For example, the
appliance might use binary trees with keys that are the names of the
objects (e.g. queues, channels, devices). It could choose to use an
in-memory relational database. We're not concerned with internal implementation
- just the external behaviour including performance to support response
times.  There may also be a need to “join” the results of internal
searches of different data structures. It is difficult to anticipate
all such requirements up front, but it is worth being aware of the
general requirement so that to some extent the data structures might
be designed to avoid such joins or to at least make them as efficient
as possible. See the WMQ scalability suggestions below for some concrete
examples.  There may also be a need for aggregation of monitoring
across multiple ISM appliances, e.g. if appliances are deployed in
availability pairs, or horizontally scaled groups. An example might
be “Show me the status of the connection from a particular client”
 - the connection could have been made to any of the available ISM
appliances, and the administrative interface may need to combine data
from those appliances to provide an aggregated response.     </p><p
>MQ scalable admin   Note that there may be an opportunity to share
concepts and technology used for the scaling of admin in Niagara and
WMQ. Work is ongoing in WMQ to provide admin at levels of scale that
the current MQExplorer interface cannot reach. There would be multiple
benefits in sharing concepts and technology where possible, so that
we do this work once and reuse it to achieving a common or consistent
user expereince across both products.  There are a number of things
that are being considered for improving scalability of  WMQ administration: </p
><p>•    The ability to register for notification events that are
generated when an interesting situation occurs – and the use of conditional
expressions to specify those situations. WMQ provides some events
already, but we could add a means to specify additional rules for
generation; turn the events into publications; and send them out to
any subscriber, even one connected via a mobile device. The product
could contain a number of predefined rules. Should this capitalise
on an existing rules engine – e.g. JRules?</p><p> •    Extension of
WMQ queries with options that would reduce the scope of queries, e.g.
provision of AND/OR clauses to MQSC commands.</p><p> •    Support
queries of objects, using a similar model to that used for topic subscriptions,
including the ability to subset based on character delimiters (such
as the '/' characters in a topic string) and to display only the elements
you have explicitly expanded in the tree. Applying this to object
names, it may be possible to render a tree view of queues, instead
of a flat list of queues. The '.' character could be used to separate
the levels in the tree, for example.</p><p> •    There are some WMQ
administrative queries that can only be answered by joining the results
from two queries. For example, "I have a full queue. How do I find
which other queues the rogue application is using?"  (Answer: use
DIS QSTATUS, find the CONNID, then DIS CONN where Connid=<connid>).
It may be necessary/beneficial to support something like a SQL JOIN
operation, rather than simple conditions like AND and OR.  </connid
></p></section>
</conbody>
</concept>
<?Pub *0000014502?>
